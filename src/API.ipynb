{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing text data for Natural Language Processing\n",
    "\n",
    "This is a short, user-oriented introduction to the Python library `cophi_toolbox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cophi_toolbox as ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API\n",
    "\n",
    "With `ct.pipe()`, you can pipe a collection of text files through several NLP tasks, and get a document-term matrix with useful attributes and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the parameters?\n",
    "\n",
    "You can use Python's built-in `help()` function to access `cophi_toolbox`'s short and sweet documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipe in module cophi_toolbox.api:\n",
      "\n",
      "pipe(directory:Union[str, pathlib.Path], pathname_pattern:str='*.*', treat_as:Union[str, NoneType]=None, encoding:str='utf-8', lowercase:bool=True, ngrams:int=1, token_pattern:str='\\\\p{L}+\\\\p{P}?\\\\p{L}+', maximum:Union[int, NoneType]=None) -> Tuple[cophi_toolbox.model.Corpus, pandas.core.frame.DataFrame]\n",
      "    Pipe a collection of text files through multiple NLP tasks.\n",
      "    \n",
      "    Parameters:\n",
      "        directory: Path to the corpus directory.\n",
      "        pathname_pattern: Glob pattern for text files.\n",
      "        treat_as: Treat text files like this suffix. If None, `pathname_pattern` is considered.\n",
      "        encoding: Encoding to use for UTF when reading.\n",
      "        lowercase: If True, all letters are lowercase.\n",
      "        ngrams: The `n` in ngram, e.g. 1 for unigram, 2 for bigram, etc.\n",
      "        token_pattern: Regex pattern for a token.\n",
      "        maximum: If not None, stop tokenizing after that much tokens.\n",
      "    \n",
      "    Returns:\n",
      "        A Corpus model object and a pandas DataFrame with metadata.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ct.pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, metadata = ct.pipe(directory=\"british-fiction-corpus\",\n",
    "                           pathname_pattern=\"**/*.txt\",  # ref.: https://en.wikipedia.org/wiki/Glob_(programming)\n",
    "                           treat_as=\".txt\",\n",
    "                           encoding=\"utf-8\",\n",
    "                           lowercase=True,\n",
    "                           ngrams=1,\n",
    "                           token_pattern=r\"\\p{L}+\\p{P}?\\p{L}+\",\n",
    "                           maximum=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful attribute would be `size`, which gives you information about the number of documents and types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "documents       10\n",
       "types        33050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the document-term matrix with the attribute `dtm`, which returns a pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1b21ad2-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad3-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad4-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      a'mighty  a'most  a'n  a'ready  a-bakin  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64       0.0     0.0  0.0      0.0      0.0   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64       0.0     1.0  0.0      0.0      0.0   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64       1.0     1.0  0.0      2.0      0.0   \n",
       "\n",
       "                                      a-be  a-beatin  a-bed  a-begging  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64   0.0       0.0    0.0        0.0   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64   0.0       0.0    0.0        0.0   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64   0.0       1.0    0.0        0.0   \n",
       "\n",
       "                                      a-bleatin  \n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64        0.0  \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64        0.0  \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dtm.iloc[:3,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `ct.pipe()` returned not only the `Corpus` object but also a `DataFrame` with metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>parent</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>british-fiction-corpus/trollope_phineas.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>trollope_phineas</td>\n",
       "      <td>c1b21ad2-9a5b-11e8-a444-002710199d64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british-fiction-corpus/dickens_bleak.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>dickens_bleak</td>\n",
       "      <td>c1b21ad3-9a5b-11e8-a444-002710199d64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>british-fiction-corpus/eliot_mill.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>eliot_mill</td>\n",
       "      <td>c1b21ad4-9a5b-11e8-a444-002710199d64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      filepath                  parent suffix  \\\n",
       "0  british-fiction-corpus/trollope_phineas.txt  british-fiction-corpus   .txt   \n",
       "1     british-fiction-corpus/dickens_bleak.txt  british-fiction-corpus   .txt   \n",
       "2        british-fiction-corpus/eliot_mill.txt  british-fiction-corpus   .txt   \n",
       "\n",
       "              title                                  uuid  \n",
       "0  trollope_phineas  c1b21ad2-9a5b-11e8-a444-002710199d64  \n",
       "1     dickens_bleak  c1b21ad3-9a5b-11e8-a444-002710199d64  \n",
       "2        eliot_mill  c1b21ad4-9a5b-11e8-a444-002710199d64  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily add additional metadata to the existing `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>parent</th>\n",
       "      <th>suffix</th>\n",
       "      <th>title</th>\n",
       "      <th>uuid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>british-fiction-corpus/trollope_phineas.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>trollope_phineas</td>\n",
       "      <td>c1b21ad2-9a5b-11e8-a444-002710199d64</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british-fiction-corpus/dickens_bleak.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>dickens_bleak</td>\n",
       "      <td>c1b21ad3-9a5b-11e8-a444-002710199d64</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>british-fiction-corpus/eliot_mill.txt</td>\n",
       "      <td>british-fiction-corpus</td>\n",
       "      <td>.txt</td>\n",
       "      <td>eliot_mill</td>\n",
       "      <td>c1b21ad4-9a5b-11e8-a444-002710199d64</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      filepath                  parent suffix  \\\n",
       "0  british-fiction-corpus/trollope_phineas.txt  british-fiction-corpus   .txt   \n",
       "1     british-fiction-corpus/dickens_bleak.txt  british-fiction-corpus   .txt   \n",
       "2        british-fiction-corpus/eliot_mill.txt  british-fiction-corpus   .txt   \n",
       "\n",
       "              title                                  uuid  year  \n",
       "0  trollope_phineas  c1b21ad2-9a5b-11e8-a444-002710199d64  1868  \n",
       "1     dickens_bleak  c1b21ad3-9a5b-11e8-a444-002710199d64  1853  \n",
       "2        eliot_mill  c1b21ad4-9a5b-11e8-a444-002710199d64  1860  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"year\"] = [1868, 1853, 1860, 1799, 1742, 1749, 1844, 1850, 1876, 1848]\n",
    "metadata.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can save it with its pandas `to_csv()` method, edit or enrich it with a spreadsheet program like Excel, and read it again with `pd.read_csv()`.\n",
    "\n",
    "> Be aware that each line in the document-term matrix must have a unique index value.\n",
    "\n",
    "The `Corpus` object also has a static method for mapping metadata (based on a [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)) to the document-term matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1868_trollope_phineas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853_dickens_bleak</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860_eliot_mill</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       a'mighty  a'most  a'n  a'ready  a-bakin  a-be  \\\n",
       "1868_trollope_phineas       0.0     0.0  0.0      0.0      0.0   0.0   \n",
       "1853_dickens_bleak          0.0     1.0  0.0      0.0      0.0   0.0   \n",
       "1860_eliot_mill             1.0     1.0  0.0      2.0      0.0   0.0   \n",
       "\n",
       "                       a-beatin  a-bed  a-begging  a-bleatin  \n",
       "1868_trollope_phineas       0.0    0.0        0.0        0.0  \n",
       "1853_dickens_bleak          0.0    0.0        0.0        0.0  \n",
       "1860_eliot_mill             1.0    0.0        0.0        0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.map_metadata(dtm=corpus.dtm,\n",
    "                    metadata=metadata,\n",
    "                    uuid=\"uuid\",  # this is the connection (or, values of this column) between metadata and document in the matrix\n",
    "                    fields=[\"year\", \"title\"],  # select one or multiple metadata fields\n",
    "                    sep=\"_\").iloc[:3,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced usage\n",
    "\n",
    "The `Corpus` object has some useful methods and attributes. In addition to various normalized or standardized document-term matrices, there are a multitude of lexical complexity measures – by document or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus vocabulary (or types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a'mighty\",\n",
       " \"a'most\",\n",
       " \"a'n\",\n",
       " \"a'ready\",\n",
       " 'a-bakin',\n",
       " 'a-be',\n",
       " 'a-beatin',\n",
       " 'a-bed',\n",
       " 'a-begging',\n",
       " 'a-bleatin']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.types[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'to', 'of', 'in', 'he', 'was', 'that', 'his', 'it']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.mfw(n=100,\n",
    "           rel_freqs=True)[:10]  # use document-term matrix with relative word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hapax legomena\n",
    "\n",
    "In corpus linguistics, a hapax legomenon is a word that occurs only once within a context, or in this case in a single text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a'mighty\",\n",
       " \"a'n\",\n",
       " 'a-bakin',\n",
       " 'a-beatin',\n",
       " 'a-begging',\n",
       " 'a-bleatin',\n",
       " 'a-bringin',\n",
       " 'a-carrying',\n",
       " 'a-collectin',\n",
       " 'a-comin']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.hapax()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop features from document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 16595 will be dropped.\n",
      "Vocabulary size before: 33050\n",
      "Vocabulary size after: 16455\n"
     ]
    }
   ],
   "source": [
    "features = corpus.mfw() + corpus.hapax()\n",
    "print(f\"A total of {len(features)} will be dropped.\")\n",
    "dtm = corpus.dtm\n",
    "\n",
    "print(f\"Vocabulary size before: {corpus.size['types']}\")\n",
    "dtm = corpus.drop(dtm=corpus.dtm,\n",
    "                  features=features)\n",
    "print(f\"Vocabulary size after: {dtm.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency spectrum\n",
    "\n",
    "How often does a frequency occur in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     12616\n",
       "2.0      4508\n",
       "3.0      2627\n",
       "4.0      1760\n",
       "5.0      1253\n",
       "6.0      1012\n",
       "7.0       863\n",
       "8.0       586\n",
       "9.0       519\n",
       "10.0      467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.freq_spectrum[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-term matrix sorted in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>of</th>\n",
       "      <th>in</th>\n",
       "      <th>he</th>\n",
       "      <th>was</th>\n",
       "      <th>that</th>\n",
       "      <th>his</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1b21ad2-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>6412.0</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>3667.0</td>\n",
       "      <td>2424.0</td>\n",
       "      <td>3373.0</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>1854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad3-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>4918.0</td>\n",
       "      <td>3706.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2642.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>1464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad4-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>4053.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         the     and      to      of      in  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64  6412.0  4226.0  5175.0  4004.0  2416.0   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64  4918.0  3706.0  2928.0  2642.0  1909.0   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64  4053.0  2979.0  2701.0  2216.0  1389.0   \n",
       "\n",
       "                                          he     was    that     his      it  \n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64  3667.0  2424.0  3373.0  2094.0  1854.0  \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64  1387.0  1194.0  1389.0  1079.0  1464.0  \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64  1135.0  1456.0  1139.0  1065.0  1129.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.sort(dtm=corpus.dtm).iloc[:3,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-term matrix with z-scores\n",
    "\n",
    "Used formula is: $$z_x = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1b21ad2-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad3-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad4-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>1.897367</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      a'mighty    a'most       a'n   a'ready  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64 -0.474342 -0.650791 -0.316228 -0.414039   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64 -0.474342  0.162698 -0.316228 -0.414039   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64  1.897367  0.162698 -0.316228  0.621059   \n",
       "\n",
       "                                       a-bakin      a-be  a-beatin     a-bed  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64 -0.316228 -0.316228 -0.316228 -0.444478   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64 -0.316228 -0.316228 -0.316228 -0.444478   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64 -0.316228 -0.316228  2.846050 -0.444478   \n",
       "\n",
       "                                      a-begging  a-bleatin  \n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64  -0.474342  -0.316228  \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64  -0.474342  -0.316228  \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64  -0.474342  -0.316228  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.zscores.iloc[:3,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-term matrix with TF-IDF scores\n",
    "\n",
    "Used formula is: $$\n",
    "        tf-idf_{t,d} \\; = \\; tf_{t,d} \\times idf_t \\; = \\; tf_{t,d}\n",
    "        \\times log(\\frac{N}{df_t})\n",
    "        $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1b21ad2-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad3-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1b21ad4-9a5b-11e8-a444-002710199d64</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      a'mighty    a'most  a'n   a'ready  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64  0.000000  0.000000  0.0  0.000000   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64  0.000000  0.000009  0.0  0.000000   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64  0.000017  0.000010  0.0  0.000035   \n",
       "\n",
       "                                      a-bakin  a-be  a-beatin  a-bed  \\\n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64      0.0   0.0  0.000000    0.0   \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64      0.0   0.0  0.000000    0.0   \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64      0.0   0.0  0.000025    0.0   \n",
       "\n",
       "                                      a-begging  a-bleatin  \n",
       "c1b21ad2-9a5b-11e8-a444-002710199d64        0.0        0.0  \n",
       "c1b21ad3-9a5b-11e8-a444-002710199d64        0.0        0.0  \n",
       "c1b21ad4-9a5b-11e8-a444-002710199d64        0.0        0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf.iloc[:3,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level model classes\n",
    "\n",
    "The `ct.pipe()` function wraps three classes:\n",
    "\n",
    "1. `Textfile` models a document on the file level.\n",
    "2. `Document` models a document on the text level.\n",
    "3. `Corpus` models a collection of documents on the corpus level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return value is a <class 'generator'>.\n",
      "Use it e.g. as a list: list(tokens) -> ['Jemand', 'mußte', 'Josef', 'K']\n"
     ]
    }
   ],
   "source": [
    "tokens = ct.find_tokens(document=\"Jemand mußte Josef K. verleumdet haben.\",\n",
    "                        pattern=\"\\w+\",\n",
    "                        maximum=4)\n",
    "\n",
    "print(f\"The return value is a {type(tokens)}.\")\n",
    "print(f\"Use it e.g. as a list: list(tokens) -> {list(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return value is also a <class 'generator'>.\n",
      "You can use it as a list, too: list(bigrams) -> ['Jemand mußte', 'mußte Josef', 'Josef K']\n"
     ]
    }
   ],
   "source": [
    "bigrams = ct.construct_ngrams(tokens=['Jemand', 'mußte', 'Josef', 'K'],\n",
    "                              n=2,\n",
    "                              sep=\" \")\n",
    "print(f\"The return value is also a {type(bigrams)}.\")\n",
    "print(f\"You can use it as a list, too: list(bigrams) -> {list(bigrams)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return value is a <class 'pandas.core.series.Series'>)\n",
      "But you can use it as a dictionary, if you want to: {'Jemand mußte': 1, 'mußte Josef': 1, 'Josef K': 1}\n"
     ]
    }
   ],
   "source": [
    "counts = ct.count_tokens(tokens=['Jemand mußte', 'mußte Josef', 'Josef K'])\n",
    "\n",
    "print(f\"The return value is a {type(counts)})\")\n",
    "print(f\"But you can use it as a dictionary, if you want to: {counts.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return value is a <class 'generator'>)\n",
      "And you can use it e.g. as a list: [[['Jemand', 'mußte']], [['Josef', 'K']], [['verleumdet', 'haben']]]\n"
     ]
    }
   ],
   "source": [
    "segments = ct.segment_fuzzy(paragraphs=[[\"Jemand\", \"mußte\", \"Josef\", \"K\"],[\"verleumdet\", \"haben\"]],\n",
    "                            segment_size=2,\n",
    "                            tolerance=0.05)\n",
    "\n",
    "print(f\"The return value is a {type(segments)})\")\n",
    "print(f\"And you can use it e.g. as a list: {list(segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/severin/kafka_derprozeß.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text -> id oder so -> metadaten\n",
    "\n",
    "spalte einer tsv datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ct.textfile(filepath=file,\n",
    "                treat_as=\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kafka_derprozeß'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.xml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/severin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Der Prozeß'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.content.strip()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 characters of 'kafka_derprozeß.xml', treated as XML: \n",
      "Der Prozeß\n"
     ]
    }
   ],
   "source": [
    "with ct.textfile(file, treat_as=\".xml\") as document:\n",
    "    print(f\"First 10 characters of '{document.title + document.suffix}', treated as XML: \\n{document.content.strip()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 39 characters of 'kafka_derprozeß.xml', treated as plain text: \n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with ct.textfile(file, treat_as=\".txt\") as document:\n",
    "    print(f\"First 39 characters of '{document.title + document.suffix}', treated as plain text: \\n{document.content.strip()[:39]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Processing XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x7f5e13f4c6c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "tree = f.parse_xml(parser=etree.XMLParser())\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jemand mußte Josef K. verleumdet haben, denn ohne daß er etwas Böses getan hätte, wurde er eines Morgens verhaftet. Die Köchin der Frau Grubach, seiner Zimmervermieterin, die ihm jeden Tag gegen acht Uhr früh das Frühstück brachte, kam diesmal nicht. Das war noch niemals geschehen. K. wartete noch ein Weilchen, sah von seinem Kopfkissen aus die alte Frau, die ihm gegenüber wohnte und die ihn mit einer an ihr ganz ungewöhnlichen Neugierde beobachtete, dann aber, gleichzeitig befremdet und hungrig, läutete er. Sofort klopfte es und ein Mann, den er in dieser Wohnung noch niemals gesehen hatte, trat ein. Er war schlank und doch fest gebaut, er trug ein anliegendes schwarzes Kleid, das, ähnlich den Reiseanzügen, mit verschiedenen Falten, Taschen, Schnallen, Knöpfen und einem Gürtel versehen war und infolgedessen, ohne daß man sich darüber klar wurde, wozu es dienen sollte, besonders praktisch erschien. »Wer sind Sie?« fragte K. und saß gleich halb aufrecht im Bett. Der Mann aber ging über die Frage hinweg, als müsse man seine Erscheinung hinnehmen, und sagte bloß seinerseits: »Sie haben geläutet?« »Anna soll mir das Frühstück bringen«, sagte K. und versuchte, zunächst stillschweigend, durch Aufmerksamkeit und Überlegung festzustellen, wer der Mann eigentlich war. Aber dieser setzte sich nicht allzulange seinen '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.xpath(\"tei:text//text()\", namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"})[31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ct.document(text=f.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Document.tokens.<locals>.<genexpr> at 0x7f5e13f82d00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['der', 'prozeß']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(d.tokens)[:2]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dropping tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prozeß']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = list(d.drop(tokens, [\"der\"]))\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Splitting by paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Der Prozeß'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.get_paragraphs(sep=\"\\n\"))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['der', 'prozeß']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.get_segments(segment_size=1000))[0][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Segmenting and tokenizing a textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 segments in 'kafka_derprozeß'.\n"
     ]
    }
   ],
   "source": [
    "segments = list(d.get_segments(segment_size=1000))\n",
    "print(f\"{len(segments)} segments in '{f.title}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"{f.title}_{n}\" for n in range(len(segments))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kafka_derprozeß_0    [der, prozeß, hdl, de, textgrid:qmx, der, anno...\n",
       "kafka_derprozeß_1    [vielleicht, noch, besaß, schätzte, er, nicht,...\n",
       "kafka_derprozeß_2    [worte, die, ich, mit, einem, mir, ebenbürtige...\n",
       "kafka_derprozeß_3    [gehen, pflegte, spät, nach, hause, kam, und, ...\n",
       "kafka_derprozeß_4    [er, dann, hinüber, die, drei, wichen, auch, s...\n",
       "kafka_derprozeß_5    [mann, aufmerksam, machte, den, er, selbst, sc...\n",
       "kafka_derprozeß_6    [ja, bloß, die, vermieterin, nun, ich, habe, a...\n",
       "kafka_derprozeß_7    [fenster, lag, und, die, müden, augen, drückte...\n",
       "kafka_derprozeß_8    [den, leib, schickt, da, sie, aber, doch, frei...\n",
       "kafka_derprozeß_9    [hat, eine, größere, summe, von, mir, geliehen...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# performance: pandas und z. b. listen statt irgendwelchen anderen standarddatentypen\n",
    "pd.Series(segments, index=labels).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"british-fiction-corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob = pathlib.Path(directory).glob(\"**/*.txt\")\n",
    "\n",
    "def lazy_reading(glob):\n",
    "    for filepath in glob:\n",
    "        yield ct.textfile(filepath)\n",
    "\n",
    "documents = pd.Series()\n",
    "for document in lazy_reading(glob):\n",
    "    t = ct.document(document.content)\n",
    "    tokens = pd.Series(t.tokens)\n",
    "    tokens.name = document.title\n",
    "    documents[document.title] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     phineas\n",
       "1        finn\n",
       "2          by\n",
       "3     anthony\n",
       "4    trollope\n",
       "5      volume\n",
       "6     chapter\n",
       "7          dr\n",
       "8        finn\n",
       "9          of\n",
       "Name: trollope_phineas, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ct.corpus(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Corpus size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "documents       10\n",
       "types        33050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'to', 'of', 'in', 'he', 'was', 'that', 'his', 'it']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_mfw(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hapax legomena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a'mighty\",\n",
       " \"a'n\",\n",
       " 'a-bakin',\n",
       " 'a-beatin',\n",
       " 'a-begging',\n",
       " 'a-bleatin',\n",
       " 'a-bringin',\n",
       " 'a-carrying',\n",
       " 'a-collectin',\n",
       " 'a-comin']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_hl()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "      <th>...</th>\n",
       "      <th>zitwitz</th>\n",
       "      <th>zoggy</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoodle</th>\n",
       "      <th>zooks</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zounds</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trollope_phineas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_bleak</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_mill</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_adam</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_joseph</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_tom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_lyndon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_david</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trollope_prime</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_vanity</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  a'mighty  a'most  a'n  a'ready  a-bakin  a-be  a-beatin  \\\n",
       "trollope_phineas       0.0     0.0  0.0      0.0      0.0   0.0       0.0   \n",
       "dickens_bleak          0.0     1.0  0.0      0.0      0.0   0.0       0.0   \n",
       "eliot_mill             1.0     1.0  0.0      2.0      0.0   0.0       1.0   \n",
       "eliot_adam             1.0     3.0  0.0      6.0      1.0   4.0       0.0   \n",
       "fielding_joseph        0.0     0.0  0.0      0.0      0.0   0.0       0.0   \n",
       "fielding_tom           0.0     0.0  0.0      0.0      0.0   0.0       0.0   \n",
       "thackeray_lyndon       0.0     0.0  0.0      0.0      0.0   0.0       0.0   \n",
       "dickens_david          0.0     3.0  0.0      0.0      0.0   0.0       0.0   \n",
       "trollope_prime         0.0     0.0  0.0      0.0      0.0   0.0       0.0   \n",
       "thackeray_vanity       0.0     0.0  1.0      0.0      0.0   0.0       0.0   \n",
       "\n",
       "                  a-bed  a-begging  a-bleatin  ...   zitwitz  zoggy  zone  \\\n",
       "trollope_phineas    0.0        0.0        0.0  ...       0.0    0.0   0.0   \n",
       "dickens_bleak       0.0        0.0        0.0  ...       0.0    0.0   1.0   \n",
       "eliot_mill          0.0        0.0        0.0  ...       0.0    0.0   0.0   \n",
       "eliot_adam          1.0        0.0        1.0  ...       0.0    0.0   0.0   \n",
       "fielding_joseph     0.0        0.0        0.0  ...       0.0    0.0   0.0   \n",
       "fielding_tom        2.0        0.0        0.0  ...       0.0    0.0   0.0   \n",
       "thackeray_lyndon    0.0        0.0        0.0  ...       1.0    0.0   0.0   \n",
       "dickens_david       0.0        1.0        0.0  ...       0.0    0.0   0.0   \n",
       "trollope_prime      0.0        1.0        0.0  ...       0.0    0.0   0.0   \n",
       "thackeray_vanity    0.0        0.0        0.0  ...       0.0    1.0   0.0   \n",
       "\n",
       "                  zoo  zoodle  zooks  zoological  zounds   zu  zuch  \n",
       "trollope_phineas  2.0     0.0    0.0         1.0     0.0  0.0   0.0  \n",
       "dickens_bleak     0.0     1.0    0.0         0.0     0.0  0.0   0.0  \n",
       "eliot_mill        0.0     0.0    0.0         1.0     0.0  0.0   0.0  \n",
       "eliot_adam        0.0     0.0    0.0         0.0     0.0  0.0   0.0  \n",
       "fielding_joseph   0.0     0.0    0.0         0.0     0.0  0.0   0.0  \n",
       "fielding_tom      0.0     0.0    1.0         0.0     2.0  1.0   1.0  \n",
       "thackeray_lyndon  0.0     0.0    0.0         0.0     0.0  0.0   0.0  \n",
       "dickens_david     0.0     0.0    0.0         0.0     0.0  0.0   0.0  \n",
       "trollope_prime    1.0     0.0    0.0         1.0     0.0  0.0   0.0  \n",
       "thackeray_vanity  0.0     0.0    0.0         0.0     0.0  0.0   0.0  \n",
       "\n",
       "[10 rows x 33050 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Sorted document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>of</th>\n",
       "      <th>in</th>\n",
       "      <th>he</th>\n",
       "      <th>was</th>\n",
       "      <th>that</th>\n",
       "      <th>his</th>\n",
       "      <th>it</th>\n",
       "      <th>...</th>\n",
       "      <th>jail-delivery</th>\n",
       "      <th>janeiro</th>\n",
       "      <th>jamais</th>\n",
       "      <th>jamaica</th>\n",
       "      <th>jam-tarts</th>\n",
       "      <th>jam-puffs</th>\n",
       "      <th>jam-pots</th>\n",
       "      <th>jaisey</th>\n",
       "      <th>jammed</th>\n",
       "      <th>zuch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trollope_phineas</th>\n",
       "      <td>6412.0</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>5175.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>3667.0</td>\n",
       "      <td>2424.0</td>\n",
       "      <td>3373.0</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_bleak</th>\n",
       "      <td>4918.0</td>\n",
       "      <td>3706.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2642.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_mill</th>\n",
       "      <td>4053.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_adam</th>\n",
       "      <td>6304.0</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>3875.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_joseph</th>\n",
       "      <td>4758.0</td>\n",
       "      <td>2474.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_tom</th>\n",
       "      <td>8171.0</td>\n",
       "      <td>4295.0</td>\n",
       "      <td>5381.0</td>\n",
       "      <td>5195.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2547.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_lyndon</th>\n",
       "      <td>5987.0</td>\n",
       "      <td>3963.0</td>\n",
       "      <td>2881.0</td>\n",
       "      <td>3432.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_david</th>\n",
       "      <td>6115.0</td>\n",
       "      <td>5613.0</td>\n",
       "      <td>4309.0</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trollope_prime</th>\n",
       "      <td>6645.0</td>\n",
       "      <td>3756.0</td>\n",
       "      <td>5501.0</td>\n",
       "      <td>3707.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_vanity</th>\n",
       "      <td>11918.0</td>\n",
       "      <td>8784.0</td>\n",
       "      <td>5581.0</td>\n",
       "      <td>5873.0</td>\n",
       "      <td>3719.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>2976.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      the     and      to      of      in      he     was  \\\n",
       "trollope_phineas   6412.0  4226.0  5175.0  4004.0  2416.0  3667.0  2424.0   \n",
       "dickens_bleak      4918.0  3706.0  2928.0  2642.0  1909.0  1387.0  1194.0   \n",
       "eliot_mill         4053.0  2979.0  2701.0  2216.0  1389.0  1135.0  1456.0   \n",
       "eliot_adam         6304.0  4220.0  3875.0  2909.0  1983.0  1649.0  1795.0   \n",
       "fielding_joseph    4758.0  2474.0  2885.0  2555.0  1512.0  1694.0  1125.0   \n",
       "fielding_tom       8171.0  4295.0  5381.0  5195.0  2800.0  2547.0  2040.0   \n",
       "thackeray_lyndon   5987.0  3963.0  2881.0  3432.0  1956.0   877.0  1724.0   \n",
       "dickens_david      6115.0  5613.0  4309.0  3701.0  2700.0  1648.0  2566.0   \n",
       "trollope_prime     6645.0  3756.0  5501.0  3707.0  2130.0  3412.0  2309.0   \n",
       "thackeray_vanity  11918.0  8784.0  5581.0  5873.0  3719.0  2565.0  2976.0   \n",
       "\n",
       "                    that     his      it  ...   jail-delivery  janeiro  \\\n",
       "trollope_phineas  3373.0  2094.0  1854.0  ...             0.0      0.0   \n",
       "dickens_bleak     1389.0  1079.0  1464.0  ...             0.0      0.0   \n",
       "eliot_mill        1139.0  1065.0  1129.0  ...             0.0      0.0   \n",
       "eliot_adam        1542.0  1252.0  1404.0  ...             0.0      0.0   \n",
       "fielding_joseph   1022.0  1309.0   770.0  ...             0.0      0.0   \n",
       "fielding_tom      1934.0  2081.0  1598.0  ...             0.0      0.0   \n",
       "thackeray_lyndon  1121.0  1025.0   746.0  ...             0.0      0.0   \n",
       "dickens_david     2279.0  1243.0  2162.0  ...             1.0      0.0   \n",
       "trollope_prime    3232.0  2153.0  2195.0  ...             0.0      0.0   \n",
       "thackeray_vanity  2264.0  2706.0  1505.0  ...             0.0      1.0   \n",
       "\n",
       "                  jamais  jamaica  jam-tarts  jam-puffs  jam-pots  jaisey  \\\n",
       "trollope_phineas     0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "dickens_bleak        0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "eliot_mill           0.0      0.0        1.0        1.0       0.0     0.0   \n",
       "eliot_adam           0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "fielding_joseph      1.0      0.0        0.0        0.0       0.0     0.0   \n",
       "fielding_tom         0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "thackeray_lyndon     0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "dickens_david        0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "trollope_prime       0.0      0.0        0.0        0.0       0.0     0.0   \n",
       "thackeray_vanity     0.0      1.0        0.0        0.0       1.0     1.0   \n",
       "\n",
       "                  jammed  zuch  \n",
       "trollope_phineas     0.0   0.0  \n",
       "dickens_bleak        0.0   0.0  \n",
       "eliot_mill           1.0   0.0  \n",
       "eliot_adam           0.0   0.0  \n",
       "fielding_joseph      0.0   0.0  \n",
       "fielding_tom         0.0   1.0  \n",
       "thackeray_lyndon     0.0   0.0  \n",
       "dickens_david        0.0   0.0  \n",
       "trollope_prime       0.0   0.0  \n",
       "thackeray_vanity     0.0   0.0  \n",
       "\n",
       "[10 rows x 33050 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sorted_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Relative word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "      <th>...</th>\n",
       "      <th>zitwitz</th>\n",
       "      <th>zoggy</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoodle</th>\n",
       "      <th>zooks</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zounds</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trollope_phineas</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_bleak</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_mill</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_adam</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_joseph</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_tom</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_lyndon</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_david</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trollope_prime</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_vanity</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  a'mighty    a'most       a'n   a'ready   a-bakin      a-be  \\\n",
       "trollope_phineas  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "dickens_bleak     0.000000  0.000010  0.000000  0.000000  0.000000  0.000000   \n",
       "eliot_mill        0.000011  0.000011  0.000000  0.000022  0.000000  0.000000   \n",
       "eliot_adam        0.000008  0.000024  0.000000  0.000047  0.000008  0.000031   \n",
       "fielding_joseph   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fielding_tom      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "thackeray_lyndon  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "dickens_david     0.000000  0.000020  0.000000  0.000000  0.000000  0.000000   \n",
       "trollope_prime    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "thackeray_vanity  0.000000  0.000000  0.000005  0.000000  0.000000  0.000000   \n",
       "\n",
       "                  a-beatin     a-bed  a-begging  a-bleatin    ...     zitwitz  \\\n",
       "trollope_phineas  0.000000  0.000000   0.000000   0.000000    ...     0.00000   \n",
       "dickens_bleak     0.000000  0.000000   0.000000   0.000000    ...     0.00000   \n",
       "eliot_mill        0.000011  0.000000   0.000000   0.000000    ...     0.00000   \n",
       "eliot_adam        0.000000  0.000008   0.000000   0.000008    ...     0.00000   \n",
       "fielding_joseph   0.000000  0.000000   0.000000   0.000000    ...     0.00000   \n",
       "fielding_tom      0.000000  0.000013   0.000000   0.000000    ...     0.00000   \n",
       "thackeray_lyndon  0.000000  0.000000   0.000000   0.000000    ...     0.00001   \n",
       "dickens_david     0.000000  0.000000   0.000007   0.000000    ...     0.00000   \n",
       "trollope_prime    0.000000  0.000000   0.000007   0.000000    ...     0.00000   \n",
       "thackeray_vanity  0.000000  0.000000   0.000000   0.000000    ...     0.00000   \n",
       "\n",
       "                     zoggy     zone       zoo   zoodle     zooks  zoological  \\\n",
       "trollope_phineas  0.000000  0.00000  0.000013  0.00000  0.000000    0.000007   \n",
       "dickens_bleak     0.000000  0.00001  0.000000  0.00001  0.000000    0.000000   \n",
       "eliot_mill        0.000000  0.00000  0.000000  0.00000  0.000000    0.000011   \n",
       "eliot_adam        0.000000  0.00000  0.000000  0.00000  0.000000    0.000000   \n",
       "fielding_joseph   0.000000  0.00000  0.000000  0.00000  0.000000    0.000000   \n",
       "fielding_tom      0.000000  0.00000  0.000000  0.00000  0.000006    0.000000   \n",
       "thackeray_lyndon  0.000000  0.00000  0.000000  0.00000  0.000000    0.000000   \n",
       "dickens_david     0.000000  0.00000  0.000000  0.00000  0.000000    0.000000   \n",
       "trollope_prime    0.000000  0.00000  0.000007  0.00000  0.000000    0.000007   \n",
       "thackeray_vanity  0.000005  0.00000  0.000000  0.00000  0.000000    0.000000   \n",
       "\n",
       "                    zounds        zu      zuch  \n",
       "trollope_phineas  0.000000  0.000000  0.000000  \n",
       "dickens_bleak     0.000000  0.000000  0.000000  \n",
       "eliot_mill        0.000000  0.000000  0.000000  \n",
       "eliot_adam        0.000000  0.000000  0.000000  \n",
       "fielding_joseph   0.000000  0.000000  0.000000  \n",
       "fielding_tom      0.000013  0.000006  0.000006  \n",
       "thackeray_lyndon  0.000000  0.000000  0.000000  \n",
       "dickens_david     0.000000  0.000000  0.000000  \n",
       "trollope_prime    0.000000  0.000000  0.000000  \n",
       "thackeray_vanity  0.000000  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 33050 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.rel_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a'mighty</th>\n",
       "      <th>a'most</th>\n",
       "      <th>a'n</th>\n",
       "      <th>a'ready</th>\n",
       "      <th>a-bakin</th>\n",
       "      <th>a-be</th>\n",
       "      <th>a-beatin</th>\n",
       "      <th>a-bed</th>\n",
       "      <th>a-begging</th>\n",
       "      <th>a-bleatin</th>\n",
       "      <th>...</th>\n",
       "      <th>zitwitz</th>\n",
       "      <th>zoggy</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoodle</th>\n",
       "      <th>zooks</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zounds</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trollope_phineas</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.518710</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_bleak</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_mill</th>\n",
       "      <td>1.897367</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eliot_adam</th>\n",
       "      <td>1.897367</td>\n",
       "      <td>1.789676</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.691256</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>1.037116</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_joseph</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fielding_tom</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.518710</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>2.846050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_lyndon</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens_david</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>1.789676</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trollope_prime</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>1.037116</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>1.449138</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thackeray_vanity</th>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.650791</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.414039</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.474342</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.846050</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.444478</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.621059</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.316228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  a'mighty    a'most       a'n   a'ready   a-bakin      a-be  \\\n",
       "trollope_phineas -0.474342 -0.650791 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "dickens_bleak    -0.474342  0.162698 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "eliot_mill        1.897367  0.162698 -0.316228  0.621059 -0.316228 -0.316228   \n",
       "eliot_adam        1.897367  1.789676 -0.316228  2.691256  2.846050  2.846050   \n",
       "fielding_joseph  -0.474342 -0.650791 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "fielding_tom     -0.474342 -0.650791 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "thackeray_lyndon -0.474342 -0.650791 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "dickens_david    -0.474342  1.789676 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "trollope_prime   -0.474342 -0.650791 -0.316228 -0.414039 -0.316228 -0.316228   \n",
       "thackeray_vanity -0.474342 -0.650791  2.846050 -0.414039 -0.316228 -0.316228   \n",
       "\n",
       "                  a-beatin     a-bed  a-begging  a-bleatin    ...     \\\n",
       "trollope_phineas -0.316228 -0.444478  -0.474342  -0.316228    ...      \n",
       "dickens_bleak    -0.316228 -0.444478  -0.474342  -0.316228    ...      \n",
       "eliot_mill        2.846050 -0.444478  -0.474342  -0.316228    ...      \n",
       "eliot_adam       -0.316228  1.037116  -0.474342   2.846050    ...      \n",
       "fielding_joseph  -0.316228 -0.444478  -0.474342  -0.316228    ...      \n",
       "fielding_tom     -0.316228  2.518710  -0.474342  -0.316228    ...      \n",
       "thackeray_lyndon -0.316228 -0.444478  -0.474342  -0.316228    ...      \n",
       "dickens_david    -0.316228 -0.444478   1.897367  -0.316228    ...      \n",
       "trollope_prime   -0.316228 -0.444478   1.897367  -0.316228    ...      \n",
       "thackeray_vanity -0.316228 -0.444478  -0.474342  -0.316228    ...      \n",
       "\n",
       "                   zitwitz     zoggy      zone       zoo    zoodle     zooks  \\\n",
       "trollope_phineas -0.316228 -0.316228 -0.316228  2.518710 -0.316228 -0.316228   \n",
       "dickens_bleak    -0.316228 -0.316228  2.846050 -0.444478  2.846050 -0.316228   \n",
       "eliot_mill       -0.316228 -0.316228 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "eliot_adam       -0.316228 -0.316228 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "fielding_joseph  -0.316228 -0.316228 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "fielding_tom     -0.316228 -0.316228 -0.316228 -0.444478 -0.316228  2.846050   \n",
       "thackeray_lyndon  2.846050 -0.316228 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "dickens_david    -0.316228 -0.316228 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "trollope_prime   -0.316228 -0.316228 -0.316228  1.037116 -0.316228 -0.316228   \n",
       "thackeray_vanity -0.316228  2.846050 -0.316228 -0.444478 -0.316228 -0.316228   \n",
       "\n",
       "                  zoological    zounds        zu      zuch  \n",
       "trollope_phineas    1.449138 -0.316228 -0.316228 -0.316228  \n",
       "dickens_bleak      -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "eliot_mill          1.449138 -0.316228 -0.316228 -0.316228  \n",
       "eliot_adam         -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "fielding_joseph    -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "fielding_tom       -0.621059  2.846050  2.846050  2.846050  \n",
       "thackeray_lyndon   -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "dickens_david      -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "trollope_prime      1.449138 -0.316228 -0.316228 -0.316228  \n",
       "thackeray_vanity   -0.621059 -0.316228 -0.316228 -0.316228  \n",
       "\n",
       "[10 rows x 33050 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.zscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Dropping types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 33050 types.\n",
      "After: 16455 types.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before: {c.dtm.shape[1]} types.\")\n",
    "\n",
    "clean = c.drop(c.dtm, c.hapax() + c.get_mfw())\n",
    "\n",
    "print(f\"After: {clean.shape[1]} types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a'mighty\",\n",
       " \"a'most\",\n",
       " \"a'n\",\n",
       " \"a'ready\",\n",
       " 'a-bakin',\n",
       " 'a-be',\n",
       " 'a-beatin',\n",
       " 'a-bed',\n",
       " 'a-begging',\n",
       " 'a-bleatin']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Complexity measures\n",
    "\n",
    "#### 3.11.1 Frequency spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     12616\n",
       "2.0      4508\n",
       "3.0      2627\n",
       "4.0      1760\n",
       "5.0      1253\n",
       "6.0      1012\n",
       "7.0       863\n",
       "8.0       586\n",
       "9.0       519\n",
       "10.0      467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.freq_spectrum[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11.2 Summed tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310189.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11.3 Summed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95205"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11.4 Corpus type-token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07266508877726802"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namenskonvention für bestimmte gruppen von maßen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.56773990445538"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.yule_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11.5 Document type-token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trollope_phineas    0.052326\n",
       "dickens_bleak       0.092136\n",
       "eliot_mill          0.095944\n",
       "eliot_adam          0.081270\n",
       "fielding_joseph     0.086144\n",
       "fielding_tom        0.063261\n",
       "thackeray_lyndon    0.095341\n",
       "dickens_david       0.068041\n",
       "trollope_prime      0.053810\n",
       "thackeray_vanity    0.069748\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kein direkt abrufbares maß, aber trotzdem zur verfügung stellen\n",
    "\n",
    "c.get_ttr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11.6 A lot more\n",
    "\n",
    "Example: Summer's index of lexical richness\n",
    "\n",
    "$S = \\frac{\\log{\\log{V}}}{\\log{\\log{N}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For whole corpus: 0.9221348672207048\n"
     ]
    }
   ],
   "source": [
    "print(f\"For whole corpus: {c.summer_s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ct.pipe(directory=\"british-fiction-corpus\",\n",
    "            suffix=\".txt\",\n",
    "            treat_as=\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- treat_as=None, schau aufs suffix, sonst treat_as.\n",
    "\n",
    "- parameterobjekte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dokument klasse: id_menschenlesbar\n",
    "    \n",
    "metadatendataframe: methode, der man dtm übergibt und sich das anzeigen lassen kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_repr_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-def0bc39519e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_repr_html'"
     ]
    }
   ],
   "source": [
    "metadata.show_df(c.dtm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
